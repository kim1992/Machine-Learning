{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 数据处理\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#绘图\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#各种模型、数据处理方法\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''数据读入'''\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "combine_df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combine_df['NameSize'] = combine_df['Name'].apply(lambda x: len(x))\n",
    "# cut将根据值本身来选择箱子均匀间隔，qcut是根据这些值的频率来选择箱子的均匀间隔\n",
    "combine_df['NameSize'] = pd.qcut(combine_df['NameSize'],5) # 分箱\n",
    "# combine_df.groupby(combine_df['Name'].apply(lambda x: x.split(', ')[1]).apply(lambda x: x.split('.')[0]))['Survived'].mean().plot()\n",
    "# plt.show()\n",
    "titles = combine_df['Name'].apply(lambda x: x.split(', ')[1]).apply(lambda x: x.split('.')[0])\n",
    "combine_df['Title'] = titles\n",
    "combine_df['Title'] = combine_df['Title'].replace(['Don','Dona', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col','Sir','Dr', 'Master'],'Mr')\n",
    "combine_df['Title'] = combine_df['Title'].replace(['Mlle','Ms'], 'Miss')\n",
    "combine_df['Title'] = combine_df['Title'].replace(['the Countess','Mme','Lady','Dr'], 'Mrs')\n",
    "df = pd.get_dummies(combine_df['Title'],prefix='Title')\n",
    "combine_df = pd.concat([combine_df,df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 0 to 417\n",
      "Data columns (total 19 columns):\n",
      "Age                    1046 non-null float64\n",
      "Cabin                  295 non-null object\n",
      "Embarked               1307 non-null object\n",
      "Fare                   1308 non-null float64\n",
      "Parch                  1309 non-null int64\n",
      "PassengerId            1309 non-null int64\n",
      "Pclass                 1309 non-null int64\n",
      "Sex                    1309 non-null object\n",
      "SibSp                  1309 non-null int64\n",
      "Survived               891 non-null float64\n",
      "Ticket                 1309 non-null object\n",
      "NameSize               1309 non-null category\n",
      "Title                  1309 non-null object\n",
      "Title_Miss             1309 non-null uint8\n",
      "Title_Mr               1309 non-null uint8\n",
      "Title_Mrs              1309 non-null uint8\n",
      "FamilySize             1309 non-null int64\n",
      "Dead_female_family     1309 non-null int64\n",
      "Survive_male_family    1309 non-null int64\n",
      "dtypes: category(1), float64(3), int64(7), object(5), uint8(3)\n",
      "memory usage: 168.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "combine_df['Fname'] = combine_df['Name'].apply(lambda x:x.split(',')[0])\n",
    "combine_df['FamilySize'] = combine_df['SibSp']+combine_df['Parch']\n",
    "dead_female_Fname = list(set(combine_df[(combine_df.Sex=='female') & (combine_df.Age>=12)\n",
    "                              & (combine_df.Survived==0) & (combine_df.FamilySize>1)]['Fname'].values))\n",
    "survive_male_Fname = list(set(combine_df[(combine_df.Sex=='male') & (combine_df.Age>=12)\n",
    "                              & (combine_df.Survived==1) & (combine_df.FamilySize>1)]['Fname'].values))\n",
    "combine_df['Dead_female_family'] = np.where(combine_df['Fname'].isin(dead_female_Fname),1,0)\n",
    "combine_df['Survive_male_family'] = np.where(combine_df['Fname'].isin(survive_male_Fname),1,0)\n",
    "combine_df = combine_df.drop(['Name','Fname'],axis=1)\n",
    "print(combine_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group = combine_df.groupby(['Title', 'Pclass'])['Age']\n",
    "combine_df['Age'] = group.transform(lambda x: x.fillna(x.median()))\n",
    "combine_df = combine_df.drop('Title', axis = 1)\n",
    "combine_df['IsChild'] = np.where(combine_df['Age'] <= 12,1,0) # 如果小于12岁则标记为1，否则0\n",
    "combine_df['Age'] = pd.cut(combine_df['Age'],5)\n",
    "combine_df = combine_df.drop('Age',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 0 to 417\n",
      "Data columns (total 18 columns):\n",
      "Cabin                  295 non-null object\n",
      "Embarked               1307 non-null object\n",
      "Fare                   1308 non-null float64\n",
      "PassengerId            1309 non-null int64\n",
      "Pclass                 1309 non-null int64\n",
      "Sex                    1309 non-null object\n",
      "Survived               891 non-null float64\n",
      "Ticket                 1309 non-null object\n",
      "NameSize               1309 non-null category\n",
      "Title_Miss             1309 non-null uint8\n",
      "Title_Mr               1309 non-null uint8\n",
      "Title_Mrs              1309 non-null uint8\n",
      "Dead_female_family     1309 non-null int64\n",
      "Survive_male_family    1309 non-null int64\n",
      "IsChild                1309 non-null int64\n",
      "FamilySize_big         1309 non-null uint8\n",
      "FamilySize_normal      1309 non-null uint8\n",
      "FamilySize_solo        1309 non-null uint8\n",
      "dtypes: category(1), float64(2), int64(5), object(4), uint8(6)\n",
      "memory usage: 131.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "combine_df['FamilySize'] = np.where(combine_df['FamilySize'] == 0, 'solo',\n",
    "                                    np.where(combine_df['FamilySize'] <= 3, 'normal','big'))\n",
    "df = pd.get_dummies(combine_df['FamilySize'], prefix='FamilySize')\n",
    "combine_df = pd.concat([combine_df, df], axis=1).drop(['SibSp', 'Parch', 'FamilySize'], axis=1)\n",
    "print(combine_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 0 to 417\n",
      "Data columns (total 19 columns):\n",
      "Cabin                   295 non-null object\n",
      "Embarked                1307 non-null object\n",
      "Fare                    1308 non-null float64\n",
      "PassengerId             1309 non-null int64\n",
      "Pclass                  1309 non-null int64\n",
      "Sex                     1309 non-null object\n",
      "Survived                891 non-null float64\n",
      "NameSize                1309 non-null category\n",
      "Title_Miss              1309 non-null uint8\n",
      "Title_Mr                1309 non-null uint8\n",
      "Title_Mrs               1309 non-null uint8\n",
      "Dead_female_family      1309 non-null int64\n",
      "Survive_male_family     1309 non-null int64\n",
      "IsChild                 1309 non-null int64\n",
      "FamilySize_big          1309 non-null uint8\n",
      "FamilySize_normal       1309 non-null uint8\n",
      "FamilySize_solo         1309 non-null uint8\n",
      "High_Survival_Ticket    1309 non-null int64\n",
      "Low_Survival_Ticket     1309 non-null int64\n",
      "dtypes: category(1), float64(2), int64(7), object(3), uint8(6)\n",
      "memory usage: 142.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "combine_df['Ticket_Lett'] = combine_df['Ticket'].apply(lambda x: str(x)[0])\n",
    "# combine_df['Ticket_Lett'] = combine_df['Ticket_Lett'].apply(lambda x: str(x))\n",
    "\n",
    "combine_df['High_Survival_Ticket'] = np.where(combine_df['Ticket_Lett'].isin(['1', '2', 'P']),1,0)\n",
    "combine_df['Low_Survival_Ticket'] = np.where(combine_df['Ticket_Lett'].isin(['A','W','3','7']),1,0)\n",
    "combine_df = combine_df.drop(['Ticket','Ticket_Lett'],axis=1)\n",
    "print(combine_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Ticket'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Users/jinjingjie/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2524\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2525\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Ticket'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-2ce80178fd12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcombine_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ticket_Lett'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ticket'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# combine_df['Ticket_Lett'] = combine_df['Ticket_Lett'].apply(lambda x: str(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcombine_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'High_Survival_Ticket'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombine_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ticket_Lett'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'P'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcombine_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Low_Survival_Ticket'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombine_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ticket_Lett'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'W'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'7'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcombine_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ticket'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Ticket_Lett'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jinjingjie/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jinjingjie/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jinjingjie/anaconda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1842\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jinjingjie/anaconda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3842\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3843\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3844\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3845\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jinjingjie/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2525\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2527\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Ticket'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "combine_df['Ticket_Lett'] = combine_df['Ticket'].apply(lambda x: str(x)[0])\n",
    "# combine_df['Ticket_Lett'] = combine_df['Ticket_Lett'].apply(lambda x: str(x))\n",
    "combine_df['High_Survival_Ticket'] = np.where(combine_df['Ticket_Lett'].isin(['1', '2', 'P']),1,0)\n",
    "combine_df['Low_Survival_Ticket'] = np.where(combine_df['Ticket_Lett'].isin(['A','W','3','7']),1,0)\n",
    "combine_df = combine_df.drop(['Ticket','Ticket_Lett'],axis=1)\n",
    "print(combine_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 0 to 417\n",
      "Data columns (total 21 columns):\n",
      "Cabin                   295 non-null object\n",
      "Fare                    1308 non-null float64\n",
      "PassengerId             1309 non-null int64\n",
      "Pclass                  1309 non-null int64\n",
      "Sex                     1309 non-null object\n",
      "Survived                891 non-null float64\n",
      "NameSize                1309 non-null category\n",
      "Title_Miss              1309 non-null uint8\n",
      "Title_Mr                1309 non-null uint8\n",
      "Title_Mrs               1309 non-null uint8\n",
      "Dead_female_family      1309 non-null int64\n",
      "Survive_male_family     1309 non-null int64\n",
      "IsChild                 1309 non-null int64\n",
      "FamilySize_big          1309 non-null uint8\n",
      "FamilySize_normal       1309 non-null uint8\n",
      "FamilySize_solo         1309 non-null uint8\n",
      "High_Survival_Ticket    1309 non-null int64\n",
      "Low_Survival_Ticket     1309 non-null int64\n",
      "Embarked_C              1309 non-null uint8\n",
      "Embarked_Q              1309 non-null uint8\n",
      "Embarked_S              1309 non-null uint8\n",
      "dtypes: category(1), float64(2), int64(7), object(2), uint8(9)\n",
      "memory usage: 135.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "combine_df.Embarked = combine_df.Embarked.fillna('S')\n",
    "df = pd.get_dummies(combine_df['Embarked'],prefix='Embarked')\n",
    "combine_df = pd.concat([combine_df,df],axis=1).drop('Embarked',axis=1)\n",
    "print(combine_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 0 to 417\n",
      "Data columns (total 21 columns):\n",
      "Fare                    1308 non-null float64\n",
      "PassengerId             1309 non-null int64\n",
      "Pclass                  1309 non-null int64\n",
      "Sex                     1309 non-null object\n",
      "Survived                891 non-null float64\n",
      "NameSize                1309 non-null category\n",
      "Title_Miss              1309 non-null uint8\n",
      "Title_Mr                1309 non-null uint8\n",
      "Title_Mrs               1309 non-null uint8\n",
      "Dead_female_family      1309 non-null int64\n",
      "Survive_male_family     1309 non-null int64\n",
      "IsChild                 1309 non-null int64\n",
      "FamilySize_big          1309 non-null uint8\n",
      "FamilySize_normal       1309 non-null uint8\n",
      "FamilySize_solo         1309 non-null uint8\n",
      "High_Survival_Ticket    1309 non-null int64\n",
      "Low_Survival_Ticket     1309 non-null int64\n",
      "Embarked_C              1309 non-null uint8\n",
      "Embarked_Q              1309 non-null uint8\n",
      "Embarked_S              1309 non-null uint8\n",
      "Cabin_isNull            1309 non-null int64\n",
      "dtypes: category(1), float64(2), int64(8), object(1), uint8(9)\n",
      "memory usage: 135.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "combine_df['Cabin_isNull'] = np.where(combine_df['Cabin'].isnull(), 0, 1)\n",
    "combine_df = combine_df.drop('Cabin', axis=1)\n",
    "print(combine_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(combine_df['Pclass'], prefix='Pclass')\n",
    "combine_df = pd.concat([combine_df, df], axis=1).drop('Pclass', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(combine_df['Sex'], prefix='Sex')\n",
    "combine_df = pd.concat([combine_df, df], axis=1).drop('Sex',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combine_df['Fare'].fillna(combine_df['Fare'].mode()[0], inplace=True)\n",
    "# print(combine_df['Fare'].value_counts())\n",
    "combine_df['Fare'] = pd.qcut(combine_df['Fare'], 3)\n",
    "df = pd.get_dummies(combine_df['Fare'], prefix='Fare').drop('Fare_(-0.001, 8.662]',axis=1)\n",
    "# print(combine_df['Fare'].value_counts())\n",
    "combine_df = pd.concat([combine_df, df], axis=1).drop('Fare', axis=1)\n",
    "# print(combine_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = combine_df.drop(['PassengerId', 'Survived'], axis=1).columns\n",
    "# print(features)\n",
    "le = LabelEncoder()\n",
    "for feature in features:\n",
    "    le = le.fit(combine_df[feature])\n",
    "    combine_df[feature] = le.transform(combine_df[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all = combine_df.iloc[:891,:].drop(['PassengerId', 'Survived'], axis=1)\n",
    "Y_all = combine_df.iloc[:891,:]['Survived']\n",
    "X_test = combine_df.iloc[891:,:].drop(['PassengerId', 'Survived'], axis=1)\n",
    "# print(X_all.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Ensemble(object):\n",
    "\n",
    "    def __init__(self, estimators):\n",
    "        self.estimator_names = []\n",
    "        self.estimators = []\n",
    "        for i in estimators:\n",
    "            self.estimator_names.append(i[0])\n",
    "            self.estimators.append(i[1])\n",
    "        self.clf = LogisticRegression()\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        for i in self.estimators:\n",
    "            i.fit(x_train, y_train)\n",
    "        x = np.array([i.predict(x_train) for i in self.estimators]).T\n",
    "        y = y_train\n",
    "        self.clf.fit(x, y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.array([i.predict(x) for i in self.estimators]).T\n",
    "        return self.clf.predict(x)\n",
    "\n",
    "    def score(self, x, y):\n",
    "        s = precision_score(y, self.predict(x))\n",
    "        return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "svc = SVC()\n",
    "rf = RandomForestClassifier(n_estimators=300,min_samples_leaf=4,class_weight={0:0.745,1:0.255})\n",
    "gbdt = GradientBoostingClassifier(n_estimators=500,learning_rate=0.03,max_depth=3)\n",
    "xgbt = XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.03)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.71000000000001\n"
     ]
    }
   ],
   "source": [
    "ensemble = Ensemble([('lr',lr),('rf',rf),('svc',svc),('gbdt',gbdt),('xgbt',xgbt)])\n",
    "score = 0\n",
    "for i in range(0, 10):\n",
    "    num_test = 0.20\n",
    "    x_train, x_cv, y_train, y_cv = train_test_split(X_all.values, Y_all.values, test_size=num_test)\n",
    "    ensemble.fit(x_train, y_train)\n",
    "#     # Y_test = ensemble.predict(X_test)\n",
    "    acc = round(ensemble.score(x_cv, y_cv) * 100 , 2)\n",
    "    score += acc\n",
    "print(score/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names may not contain [, ] or <",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-a54e3cd4ac36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m submission = pd.DataFrame({'PassengerId': test_df['PassengerId'],\n\u001b[1;32m      5\u001b[0m                            'Survived': Y_test})\n",
      "\u001b[0;32m<ipython-input-64-63444579517e>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_train, y_train)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jinjingjie/anaconda/lib/python3.6/site-packages/xgboost-0.7-py3.6.egg/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model)\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m             train_dmatrix = DMatrix(X, label=training_labels,\n\u001b[0;32m--> 500\u001b[0;31m                                     missing=self.missing, nthread=self.n_jobs)\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         self._Booster = train(xgb_options, train_dmatrix, self.n_estimators,\n",
      "\u001b[0;32m/Users/jinjingjie/anaconda/lib/python3.6/site-packages/xgboost-0.7-py3.6.egg/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jinjingjie/anaconda/lib/python3.6/site-packages/xgboost-0.7-py3.6.egg/xgboost/core.py\u001b[0m in \u001b[0;36mfeature_names\u001b[0;34m(self, feature_names)\u001b[0m\n\u001b[1;32m    665\u001b[0m                        \u001b[0;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'['\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m']'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'<'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                        for f in feature_names):\n\u001b[0;32m--> 667\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feature_names may not contain [, ] or <'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0;31m# reset feature_types also\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: feature_names may not contain [, ] or <"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "ensemble.fit(X_all, Y_all)\n",
    "Y_test = ensemble.predict(X_test).astype(int)\n",
    "submission = pd.DataFrame({'PassengerId': test_df['PassengerId'],\n",
    "                           'Survived': Y_test})\n",
    "submission.to_csv('submission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
